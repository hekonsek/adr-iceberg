# Use Apache Iceberg version **1.10 or later** for the data lake stack

## Context

We want a clear, enforceable baseline for Apache Iceberg so that engine integrations (Flink, PyIceberg, Java SDKs) remain aligned and so that feature use (branching, row-level ops, delete files, partition evolution, spec/format versions) is predictable across projects and environments.

Version 1.10 introduces **official Flink 2.0 support**, enabling us to align with the new Flink major release we plan to adopt as the primary stream processing engine.

## Decision

Adopt Apache Iceberg version 1.10 or later as the minimum supported version across the platform. All production jobs, services, and tools that read or write Iceberg tables must:

- Use Iceberg **>= 1.10.x** libraries/connectors/drivers.
- Use engine connectors (Flink, Spark, Trino/Presto, PyIceberg) that are officially compatible with Iceberg 1.10+.

This decision establishes a **platform baseline**. Teams can use **newer** Iceberg versions as they become the platform baseline via the upgrade process below; older (<1.10) are disallowed for production.

## Consequences

✅ Positive

* Reduced integration risk across engines.
* Faster incident triage with one known baseline.
* Easier enablement of advanced features (row-level deletes, branching) with consistent behavior.
* Immediate compatibility with Flink 2.0, aligning with our future engine roadmap.

⚠️ Negative / Mitigations

* Some components (like connectors or tooling) may not be compatibile with the latest Iceberg version.
* Upgrade discipline required.

## Alternatives considered

- **Allow version freedom**: Leads to format/feature drift, frequent breakages, and unbounded support matrix. AI agents cannot support developerts efficiently.
- **Pin to a specific minor version (e.g., 1.10.x only)**: Predictable, but slows CVE/bugfix uptake and adoption of new Iceberg features.
